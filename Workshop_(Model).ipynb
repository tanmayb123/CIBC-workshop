{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JmMktKhYwgnp"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from typing import Dict, Tuple\n",
        "from google.colab import drive\n",
        "import numpy as np\n",
        "import pickle\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B2PU9gD1x3tC"
      },
      "outputs": [],
      "source": [
        "# Load the data from Google Drive\n",
        "def load_data_from_drive(folder_name: str) -> Tuple[np.ndarray, np.ndarray, Dict[int, str]]:\n",
        "    drive.mount('/content/drive')\n",
        "    folder_path = os.path.join('/content/drive/My Drive', folder_name)\n",
        "    images = np.load(os.path.join(folder_path, 'images.npy'))\n",
        "    labels = np.load(os.path.join(folder_path, 'labels.npy'))\n",
        "    with open(os.path.join(folder_path, 'class_mapping.pkl'), 'rb') as f:\n",
        "        class_dict = pickle.load(f)\n",
        "    print(f\"Loaded {len(images)} images and labels from {folder_name} in Google Drive\")\n",
        "    return images, labels, class_dict\n",
        "\n",
        "# Create the Keras model for fine-tuning\n",
        "def create_model_for_finetuning(num_classes: int) -> tf.keras.Model:\n",
        "    base_model = tf.keras.applications.convnext.ConvNeXtLarge(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "    x = base_model.output\n",
        "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "    x = tf.keras.layers.Dropout(0.5)(x)\n",
        "    predictions = tf.keras.layers.Dense(num_classes, activation='softmax')(x)\n",
        "    model = tf.keras.Model(inputs=base_model.input, outputs=predictions)\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = False\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X3KWUIWHx6vv"
      },
      "outputs": [],
      "source": [
        "images, labels, class_dict = load_data_from_drive('michael_tanmay_ibm_ai_workshop')\n",
        "print(images.shape)\n",
        "print(labels.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fyRiYiyxyHgQ"
      },
      "outputs": [],
      "source": [
        "images = tf.keras.applications.convnext.preprocess_input(images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IJWauQ-myQvj"
      },
      "outputs": [],
      "source": [
        "num_classes = len(class_dict)\n",
        "model = create_model_for_finetuning(num_classes=num_classes)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CFKoDI3x0kMI"
      },
      "outputs": [],
      "source": [
        "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
        "loss = 'sparse_categorical_crossentropy'\n",
        "model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nYnga1iG29sV"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "i = list(range(len(images)))\n",
        "random.shuffle(i)\n",
        "images = images[i]\n",
        "labels = labels[i]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AJUM1Jiy0u5x"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "shuffle = True\n",
        "validation_split = 0.1\n",
        "epochs = 2\n",
        "model.fit(images, labels, batch_size=batch_size, shuffle=shuffle, validation_split=validation_split, epochs=epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t6-ak9302j_4"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "from google.colab import files\n",
        "\n",
        "def load_image_from_upload() -> Image.Image:\n",
        "    \"\"\"\n",
        "    Let the user upload an image into the Colab cell interface and load it using Pillow.\n",
        "\n",
        "    Returns:\n",
        "        A Pillow Image object of the uploaded image.\n",
        "    \"\"\"\n",
        "    uploaded = files.upload()\n",
        "    img_bytes = BytesIO(uploaded[next(iter(uploaded))])\n",
        "    img = Image.open(img_bytes)\n",
        "    return img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HFl_NeaX4OEt"
      },
      "outputs": [],
      "source": [
        "image = load_image_from_upload().convert(\"RGB\").resize((224, 224))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pdfBUXg64Pkl"
      },
      "outputs": [],
      "source": [
        "image = tf.keras.applications.convnext.preprocess_input(np.array(image)[None, ...])\n",
        "pred = model.predict(image)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YTjEAqlNE0XO"
      },
      "outputs": [],
      "source": [
        "best = pred.argsort()[-5:]\n",
        "names = [class_dict[x] for x in best]\n",
        "scores = pred[best]\n",
        "\n",
        "for i in zip(best, names, scores):\n",
        "    print(i)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}